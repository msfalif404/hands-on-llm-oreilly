{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P2ZWkdM831V",
        "outputId": "6e394903-b577-42de-a8e1-b982a3245e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python==0.2.69\n",
            "  Using cached llama_cpp_python-0.2.69.tar.gz (42.5 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.69)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.2.69) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.69) (3.0.2)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.69-cp311-cp311-linux_x86_64.whl size=55723657 sha256=b7fc81ec70735e2094c87ba588a9fe5811a21c28bf50da5ea1949cb5642fc0f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/ff/b4dba97fbd16e731705b262602ba8f3b672bf4bde54ea0c104\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.69\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain>=0.1.17 openai>=1.13.3 langchain_openai>=0.1.6 transformers>=4.40.1 datasets>=2.18.0 accelerate>=0.27.2 sentence-transformers>=2.5.1 duckduckgo-search>=5.2.2 langchain_community\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python==0.2.69"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSS8Mocc87yt",
        "outputId": "4bce0cf0-5d83-418a-820f-9e0d031ff337"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-14 05:52:29--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.34, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1749883949&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTg4Mzk0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IPceNA%7EDlg9LlNzMSFvRsuXzDlymwjdCBVHHa090iFuZpFByrdhg8jOmfQdx22ZkOIlfDdPI3gx7ttzSG4UK6CS5A253F9e4r6PHEL3UisfnEkb8vS2DROwGMgAF3JxqDU1szYJpo0qP0FHXR7AbZdsWbWSdqPU%7E39SuP%7EvVOwZg2RTNCzR295f4Zsv7xfg16PyhB4rOkhKedO61T1E0UjRiJ8M44J-h2BSu8bNncpjM8mzOX1wEftijyksH8sChPRRppe0Ck0BU8DwAcgIf1eiKXYIfObVN48L4VSBm0vjLdJqdwFhvuark8MZB8LSi%7E8FsMZWWdUmLmuN9imRrjw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-14 05:52:29--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1749883949&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTg4Mzk0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IPceNA%7EDlg9LlNzMSFvRsuXzDlymwjdCBVHHa090iFuZpFByrdhg8jOmfQdx22ZkOIlfDdPI3gx7ttzSG4UK6CS5A253F9e4r6PHEL3UisfnEkb8vS2DROwGMgAF3JxqDU1szYJpo0qP0FHXR7AbZdsWbWSdqPU%7E39SuP%7EvVOwZg2RTNCzR295f4Zsv7xfg16PyhB4rOkhKedO61T1E0UjRiJ8M44J-h2BSu8bNncpjM8mzOX1wEftijyksH8sChPRRppe0Ck0BU8DwAcgIf1eiKXYIfObVN48L4VSBm0vjLdJqdwFhvuark8MZB8LSi%7E8FsMZWWdUmLmuN9imRrjw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.35.37.129, 13.35.37.124, 13.35.37.125, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.35.37.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7643295904 (7.1G) [binary/octet-stream]\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-fp16.gguf.1’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   7.12G  19.0MB/s    in 85s     \n",
            "\n",
            "2025-06-14 05:53:55 (85.5 MB/s) - ‘Phi-3-mini-4k-instruct-fp16.gguf.1’ saved [7643295904/7643295904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Chain"
      ],
      "metadata": {
        "id": "pFHAN-ClKCDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LlamaCpp\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/Phi-3-mini-4k-instruct-fp16.gguf.1\",\n",
        "    n_gpu_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "eUyjwZcZ89f3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is 1 + 1 ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UhyUwwAK9LdU",
        "outputId": "700cfcc8-e17b-464f-bd11-6b1f51777fe5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n<|assistant|> The answer to 1 + 1 is 2.\\n\\nThis question falls under basic arithmetic, a fundamental topic in mathematics that deals with numbers and the operations performed on them: addition being one of these operations where two or more quantities are combined into a larger amount.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"<s><|user|>\n",
        "{input_prompt}<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input_prompt\"]\n",
        ")"
      ],
      "metadata": {
        "id": "tv3phbPvA4uJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain = prompt | llm"
      ],
      "metadata": {
        "id": "CxYPZBVxBPMB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain.invoke(\n",
        "    {\n",
        "        \"input_prompt\":\"Hi! My name is Falif. What is 1 + 1 ?\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ds7VOY4tBV1y",
        "outputId": "44a12ebb-559f-4cea-da69-f0565a2537d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello Falif! The answer to 1 + 1 is 2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Chain"
      ],
      "metadata": {
        "id": "SbxqUuqoKE17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "template = \"\"\"<s><|user|>\n",
        "Create a title for a story about {summary}. Only return the title.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "title_prompt = PromptTemplate(template=template, input_variables=[\"summary\"])\n",
        "title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SMCAuLcHqzl",
        "outputId": "c4ef7aa4-af2a-40ae-f4a9-a5cfb20affd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-3958448897>:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title.invoke({\"summary\": \"A girl that lost her mother.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz9puFiDIHe0",
        "outputId": "84c0ec99-978a-4726-8ad5-58e35cd5ac8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'A girl that lost her mother.',\n",
              " 'title': ' \"Lost in Grief: The Journey of a Girl Without Her Mother\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"<s><|user|>\n",
        "Describe the main character of a story about {summary} with the title {title}.\n",
        "Use only two sentences.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "character_prompt = PromptTemplate(template=template, input_variables=[\"summary\",\"title\"])\n",
        "character = LLMChain(llm=llm, prompt=character_prompt, output_key=\"character\")"
      ],
      "metadata": {
        "id": "GHgUpbN_ISsy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"<s><|user|>\n",
        "Create a story about {summary} with the title {title}. The main character is: {character}.\n",
        "Only return the story and it cannot be longer than one paragraph.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "story_prompt = PromptTemplate(template=template, input_variables=[\"summary\",\"title\",\"character\"])\n",
        "story = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
      ],
      "metadata": {
        "id": "ddeK15m6IsAT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = title | character | story"
      ],
      "metadata": {
        "id": "VVlJ6REvJVYy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke(\"A girl that lost her mother\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dLp1D3mJZ1S",
        "outputId": "4ac696bd-94b4-4421-836c-0375e7bb732e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'A girl that lost her mother',\n",
              " 'title': ' \"Finding Light Amidst Loss: The Journey of Emily After Her Mother\\'s Departure\"',\n",
              " 'character': ' Emily is an introspective and resilient young woman, who struggles to cope with the profound loss of her mother while seeking solace in nature and creative outlets like painting and writing poetry. Throughout her journey, she learns to embrace self-love, healing, and finding strength within herself as a beacon of light amidst her grief.',\n",
              " 'story': \" Finding Light Amidst Loss: The Journey of Emily After Her Mother's Departure follows the introspective and resilient young woman, Emily, as she grapples with the profound loss of her mother. As a means to cope with her grief, Emily immerses herself in nature and creative endeavors such as painting landscapes and writing heartfelt poetry. Throughout this journey, she learns that self-love, healing, and inner strength are essential for finding light amidst the darkness of her loss. Along the way, Emily discovers that honoring her mother's memory by embracing life with courage is a testament to her mother's love, ultimately allowing herself to blossom into a beacon of light even in times of sorrow.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory"
      ],
      "metadata": {
        "id": "kAHvDELmJ9wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain.invoke(\n",
        "    {\n",
        "        \"input_prompt\":\"Hi! My name is Falif. What is 1 + 1 ?\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "inMSo3NCJ78z",
        "outputId": "97ca8102-df65-4a4e-93a4-7efd208f6538"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The answer to 1 + 1 is 2. This is a basic arithmetic operation, where you are adding one unit to another unit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain.invoke({\"input_prompt\": \"What is my name >\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "qHtxAkC_KMbh",
        "outputId": "6b4ba242-df85-4f74-e2ca-c80bf2375169"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I'm unable to determine your name as I don't have the ability to access personal data or information. However, if you provide me with context or details about where this question may be coming from, I might be able to assist you better!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"<s><|user|>Current conversation:{chat_history}\n",
        "\n",
        "{input_prompt}<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input_prompt\",\"chat_history\"]\n",
        ")"
      ],
      "metadata": {
        "id": "ehISb47zLpeg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConversationBufferMemory"
      ],
      "metadata": {
        "id": "UxL0I8dxPX4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "MxO_-xlIMBoQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"Hi, my name is Falif. What is 1 + 1 ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTmjD-fCMVpo",
        "outputId": "0273565e-3ff5-43b2-8940-4653c19ed5f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'Hi, my name is Falif. What is 1 + 1 ?',\n",
              " 'chat_history': '',\n",
              " 'text': \" The sum of 1 + 1 is 2.\\n\\nHere's a brief explanation for clarity: When you add one unit to another unit, it results in two units altogether. This basic arithmetic operation is fundamental and widely applicable across various fields.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What is my name ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2RMFVXkMuA3",
        "outputId": "d0046e8b-bb8d-42ab-b431-ff575cdddff9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What is my name ?',\n",
              " 'chat_history': \"Human: Hi, my name is Falif. What is 1 + 1 ?\\nAI:  The sum of 1 + 1 is 2.\\n\\nHere's a brief explanation for clarity: When you add one unit to another unit, it results in two units altogether. This basic arithmetic operation is fundamental and widely applicable across various fields.\",\n",
              " 'text': ' Your name is Falif.\\n\\nThis response directly answers the question about your name based on the previous part of the conversation where you introduced yourself as \"Falif.\"\\n\\nNow, let\\'s address any further inquiries or tasks you might have!'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "CHRrcvXYPbqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dexMWqNaNPHu",
        "outputId": "8d139c4d-6d26-4639-8e79-628bded6e439"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-1275254419>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(input_prompt=\"Hi! My name is Falif and I am 23 years old. What is 1 + 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "I-v6O-E9NxWu",
        "outputId": "850ccc02-781d-4d53-8e3a-a1c4fb233119"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Falif, it's nice to meet you too! When we talk about simple arithmetic like addition, the answer to 1 + 1 is quite straightforward—it equals 2. Remember that these foundational skills are part of a broader range of knowledge and experiences that shape who you are beyond your age. How can I assist you further today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(input_prompt=\"What is 3 + 3 ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Z7AQNjQ1N4uu",
        "outputId": "f4599ec4-367e-418d-9c90-8d9fdaf1b18f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Absolutely, Falif! When we add the numbers 3 and 3 together, the sum is 6. Just like with any basic math operation, it's always great to explore more complex concepts as you continue learning! How else may I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What is my name ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwzeoFTgOOtu",
        "outputId": "7f39e5c2-e8f9-4b8c-a030-5314a6524e58"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What is my name ?',\n",
              " 'chat_history': \"Human: Hi! My name is Falif and I am 23 years old. What is 1 + 1\\nAI:  Hello Falif, it's nice to meet you too! When we talk about simple arithmetic like addition, the answer to 1 + 1 is quite straightforward—it equals 2. Remember that these foundational skills are part of a broader range of knowledge and experiences that shape who you are beyond your age. How can I assist you further today?\\nHuman: What is 3 + 3 ?\\nAI:  Absolutely, Falif! When we add the numbers 3 and 3 together, the sum is 6. Just like with any basic math operation, it's always great to explore more complex concepts as you continue learning! How else may I assist you today?\",\n",
              " 'text': ' Your name is Falif, as mentioned in your previous statement: \"Hello Falif, it\\'s nice to meet you too!\" Is there anything specific you would like to know or discuss further?'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What is my age ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICZw_IpdOh1n",
        "outputId": "27332d78-5e4b-4b1b-94bb-2404664c22e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What is my age ?',\n",
              " 'chat_history': 'Human: What is 3 + 3 ?\\nAI:  Absolutely, Falif! When we add the numbers 3 and 3 together, the sum is 6. Just like with any basic math operation, it\\'s always great to explore more complex concepts as you continue learning! How else may I assist you today?\\nHuman: What is my name ?\\nAI:  Your name is Falif, as mentioned in your previous statement: \"Hello Falif, it\\'s nice to meet you too!\" Is there anything specific you would like to know or discuss further?',\n",
              " 'text': \" I'm an AI and don't have access to personal data such as your age. However, I can help answer questions about general topics! If you need assistance with something else, feel free to ask.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Summary"
      ],
      "metadata": {
        "id": "fxwBlMQlPf9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt_template = \"\"\"<s><|user|>Summarize the conversations and update with the new lines.\n",
        "\n",
        "Current summary:\n",
        "{summary}\n",
        "\n",
        "New lines of conversation:\n",
        "{new_lines}\n",
        "\n",
        "New summary:<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "summary_prompt = PromptTemplate(\n",
        "    template=summary_prompt_template,\n",
        "    input_variables=[\"new_lines\",\"summary\"]\n",
        ")"
      ],
      "metadata": {
        "id": "IOBrBXPUPdYB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", prompt=summary_prompt)\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "JTDKbfZQQfoU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"Hi! My name is Muhammad Sya'bani Falif. What is 1 + 1 ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGQFwSDWQ2Vc",
        "outputId": "e240e18c-6052-4b1d-fdea-94e3d73bc130"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': \"Hi! My name is Muhammad Sya'bani Falif. What is 1 + 1 ?\",\n",
              " 'chat_history': '',\n",
              " 'text': \" Hello Muhammad Sya'bani Falif, the sum of 1 + 1 is 2.\\n\\nIf you have any other questions or need further assistance, feel free to ask!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What is my name ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJzl4wNHUrWA",
        "outputId": "d1b3a803-42e7-4fb8-8ea2-67eaa57d186b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What is my name ?',\n",
              " 'chat_history': \" New summary: Muhammad Sya'bani Falif inquired about the result of 1+1 and was informed that it equals 2; no additional queries were made.\",\n",
              " 'text': \" As an AI, I don't have access to personal data such as names unless it has been shared with me during our conversation. Therefore, I cannot determine your name from the information provided in this interaction about a math question. If you'd like to share your name for further context or assistance, feel free to do so.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What was the first question i asked ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9HE0V6rTvnf",
        "outputId": "f7176c1d-2ff1-4f12-ac55-168be79e81a3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What was the first question i asked ?',\n",
              " 'chat_history': \" Muhammad Sya'bani Falif asked about the result of 1+1 and was told it equals 2; later, he inquired about his name but received information that as an AI, I don't have access to personal data unless shared during our conversation.\",\n",
              " 'text': ' The first question you asked was: \"What is the result of 1+1?\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.invoke({\"input_prompt\": \"What was the result you given ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jUbIEfsU1lq",
        "outputId": "55c538d8-c7c6-49f4-9ca4-3bf1fa7a8c2f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_prompt': 'What was the result you given ?',\n",
              " 'chat_history': \" Muhammad Sya'bani Falif initially inquired about the result of 1+1, which equals 2. He then asked for information regarding his name and received a response stating that as an AI, I don't have access to personal data unless shared during our conversation. Additionally, he later confirmed his initial question by asking what it was.\",\n",
              " 'text': \" The result I provided initially when Muhammad Sya'bani Falif inquired about 1+1 was 2.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mSuH8GvbR3J",
        "outputId": "f39b8ebe-f74c-413b-c184-f915c79e022a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': \" Muhammad Sya'bani Falif asked for the result of 1+1, which equals 2, and confirmed his initial question by inquiring again about the response. The AI reiterated that it doesn't have access to personal data unless shared during their conversation but provided the answer regarding the mathematical query.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "AzmPogztegmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "patPtyhtehYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"MY_KEY\"\n",
        "openai_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "kjk7D7mognfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "react_template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Tought/Action/Action Input / Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final answer: the final answer the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=react_template,\n",
        "    input_variables=[\"tools\",\"tool_names\",\"input\",\"agent_scratchpad\"]\n",
        ")"
      ],
      "metadata": {
        "id": "lytPPfI_g4-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, Tool\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "\n",
        "search = DuckDuckGoSearchResults()\n",
        "search_tool = Tool(\n",
        "    name=\"duckduck\",\n",
        "    description=\"A web search engine. Use this to as a search engine for general queries.\",\n",
        "    func=search.run\n",
        ")\n",
        "\n",
        "tools = load_tools([\"llm-math\"], llm=openai_llm)\n",
        "tools.append(search_tool)"
      ],
      "metadata": {
        "id": "rii6koB4praN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "agent = create_react_agent(openai_llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "AaYZnDYUqbg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"What is the current price of a MacBook Pro in USD? How much would it cost in EUR if the exchange rate is 0.85 EUR for 1 USD.\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "_CoQSmp-quJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}